{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents <a id='top'></a>\n",
    "\n",
    "1. <a href=#np>NumPy</a>\n",
    "1. <a href=#pandas>Pandas</a>\n",
    "    1. <a href=#pandas>Series</a>\n",
    "    1. <a href=#df>DataFrames</a>\n",
    "    1. <a href=#functions>Applying Functions to DataFrame</a>\n",
    "    1. <a href=#categorical>Categorical Variables</a>\n",
    "    1. <a href=#split>Split-Apply-Transform</a>\n",
    "    1. <a href=#multiple>Working with Multiple DataFrames</a>\n",
    "1. <a href=#ref>References and Links</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# %precision 4\n",
    "# %matplotlib inline\n",
    "\n",
    "# pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='np'></a>\n",
    "# 1. NumPy\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "The basic object in this package is the `ndarray` object, which can represent *n*-dimensional arrays of homogeneous data types. This is the key difference between NumPy and Pandas objects -- while Pandas objects are also tabular in nature, they allow you to deal with inhomogenous objects. Specifically, Pandas' `DataFrame`s allow columns to be of different types.\n",
    "\n",
    "An `ndarray` object is an *n*-dimensional array (i.e., a [tensor](https://www.i2tutorials.com/wp-content/uploads/2019/09/Tensor-Datatype-and-Ranks-1i2tutorials.jpg)) of elements, indexed by a tuple of non-negative integers.\n",
    "\n",
    "The dimensions of the array are referred to as **axes** in NumPy: a three-dimensional array will have three axes.\n",
    "\n",
    "Each array has several attributes. These include:\n",
    "* `ndim`: the number of axes/dimensions.\n",
    "* `shape`: a tuple describing the length of each dimension.\n",
    "* `size`: the total number of elements in the array. This is a product of the integers in the shape attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([(1.5, 2, 3), (4, 5, 6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.size # the number of elements in \"arr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Creation\n",
    "\n",
    "One way to create an array containing regular sequences is to use the `np.arange()` function. This creates a sequence of integers, with a specified separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.arange(0, 10, 3)\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of an `ndarray` is given by a tuple. Note that an array of shape (4,) is different from one with shape (4, 1). The former has only **1 dimension**, while the latter has **2 dimensions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_vect = seq.reshape(4, 1)\n",
    "col_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an array of regularly spaced **real numbers**, use `np.linspace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr_real = np.linspace(start = 0.2, stop = 3.3, num = 24).reshape(2, 3, 4)  \n",
    "arr_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(24).reshape(4, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we need to create a placeholder array with the appropriate dimensions, and then fill it in later. This is preferrable to growing an array by appending to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3, 5)) # there is also an np.ones() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of specifying the dimensions of an array ourselves, we can create arrays of zeros or ones in the shape of other existing arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates an array of zeros, of the same shape as \"arr_real\".\n",
    "np.ones_like(arr_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice Operator in Multiple Dimensions\n",
    "\n",
    "Multidimensional NumPy arrays can be accessed with comma separated slice notation. When fewer indices are provided than the number of axes, the missing indices are considered complete slices for the remaining dimensions.\n",
    "\n",
    "By the way, when printing, the *last* axis will be printed left-to-right, and the second last axis will be printed from top-to-bottom. The remaining axes will be printed with a line in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples based on this array. Try to guess what each will return before you run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[0, 2, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[1, 0:3:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[:, 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples using Boolean indexing, which means that we use an array of `True` and `False` entries to determine which elements to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[arr_real > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a seed allows for reproducibility of random number generation\n",
    "# across sessions.\n",
    "np.random.seed(5003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(3, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randn(3, 5)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise addition.\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiplication: NOT matrix multiplication.\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication (need to transpose \"b\" to match get the right dimensions).\n",
    "# We can also do \"a @ b.T\".\n",
    "a.dot(b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "2 * a + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy enough to guess what happened there, but what if we added a 4 x 5 array to a 2 x 1 x 5 array? In general what would happen if we operated on two arrays with different shapes? \n",
    "\n",
    "That's when the broadcasting rules come into play.\n",
    "\n",
    "1. If all input arrays do not have the same number of dimensions, a \"1\" will be *pre-pended* to the **shapes** of the smaller arrays until all the arrays have the same number of dimensions.\n",
    "2. Arrays with size 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4)           # shape           4\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x.reshape((4, 1))      # shape       4 x 1\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx + x                     # shape       4 x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x` acts like an array with size (1, 4) in the addition above, and rule 2 applies for `xx`.\n",
    "The following code gives us the same output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(xx, 4) + x.reshape((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ones(5)           # shape           5\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx + y                  # shape        4 x 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = np.ones((3, 4))\n",
    "x + z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real.mean(axis = 0) # mean across the 0th (\"first\") axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-left element comes from the mean of `arr_real[0, 0, 0]` and `arr_real[1, 0, 0]`. Similarly, the element to the right of it comes from the mean of `arr_real[0, 0, 1]` and `arr_real[1, 0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(arr_real[0, 0, 1] + arr_real[1, 0, 1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real.mean(axis = (0, 1)) # the mean across the first two axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real.mean(axis = 2) # which is the mean across the third axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `arr_real[0]` is a 2D array, with shape (3, 4). Suppose we wish to compute the row means. This means we have to apply the operation by the column axis (axis = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[0].mean(axis = 1) # the mean across the second axis of arr_real[0], not of arr_real itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to identify the row with the largest mean, we use `argmax()` on the resulting array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_real[0].mean(axis = 1).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas'></a>\n",
    "# 2. Pandas\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "## Series \n",
    "\n",
    "A *Series* is a one-dimensional labeled array. The axis labels are referred to as the **index**. The simplest way to create a Series is to pass a sequence and an index to `pd.Series()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.Series(list(range(2010, 2013) ) * 3)\n",
    "\n",
    "team = [\"Barcelona\", \"RealMadrid\", \"Valencia\"] * 3\n",
    "team.sort()\n",
    "team = pd.Series(team)\n",
    "\n",
    "wins = pd.Series([30, 28, 32, 29, 32, 26, 21, 17, 19])\n",
    "draws = pd.Series([6, 7, 4, 5, 4, 7, 8, 10, 8])\n",
    "losses = pd.Series([2, 3, 2, 4, 2, 5, 9, 11, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access particular values, we can use the slice operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins[0:6:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a Series object to an `ndarray`, we use the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify an index, we can use it to access values in the Series. With Pandas, using the slice operator with labels is inclusive on both sides!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(5), \n",
    "             index=['a', 'b', 'c', 'd', 'e'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['a', 'c']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when you combine the slice operator with label-based indexing. Unlike vanilla Python, Pandas includes **both** end-points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='df'></a>\n",
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *DataFrame* is a 2-dimensional labeled data structure with possibly **different** data types. It is the most commonly used Pandas object. The *index* of a DataFrame refers to the row labels (axis 0). The *columns* refer to the column labels (axis 1).\n",
    "\n",
    "DataFrames can be constructed from Series, dictionaries, lists and 2-d arrays. For our course, we will typically create a DataFrame directly from a file.\n",
    "\n",
    "We can create a DataFrame from the earlier series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laliga = pd.DataFrame({'Year': year,\n",
    "              'Team': team,\n",
    "              'Wins': wins,\n",
    "              'Draws': draws,\n",
    "              'Losses': losses\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect a DataFrame, we can use `info()`, `head()` and `tail()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laliga.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "laliga.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also export the DataFrame to disk as plaintext (e.g., JSON, CSV, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laliga.to_json('../data/laliga.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame from NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5003)\n",
    "x = np.random.randn(12, 5)\n",
    "x_df = pd.DataFrame(x, columns = list('ABCDE')) # list(string) creates a list of its characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert DataFrames back to ndarrays.\n",
    "x_df.to_numpy() == x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data\n",
    "\n",
    "The CSV file read here contains the happiness scores of 164 countries from 2015 to 2017. Click [here](https://worldhappiness.report/ed/2017/) for a full report on the dataset.\n",
    "\n",
    "The final score was based on many other factors (such as GDP per capita, family, freedom etc) which is included in the file as well. We will simplify things by just reading in the country, final score computed and year.\n",
    "\n",
    "In each year, not all of the 164 countries had their scores surveyed and taken. This results in some countries having missing values (`NaN`) in certain years.\n",
    "\n",
    "Besides reading in CSV formats, pandas can read in tab-separated files, Excel files and HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ = pd.read_csv('../data/happiness_report.csv', header = 0, na_values = 'NA')\n",
    "\n",
    "happ.head()\n",
    "#happ.tail()\n",
    "#happ.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ['Govt.Corruption'].plot(kind = \"hist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Selection\n",
    "\n",
    "Row selection can be done with integers in the slice operator. In practice, this is not used, because we typically wish to select a set of rows based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ[10:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select columns, you may use a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ[['GDP', 'Freedom']] # note the difference with happ['GDP']\n",
    "# happ.GDP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we are not working with numpy arrays, so this will not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ[0:10, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Selecting Data\n",
    "\n",
    "The two main methods of advanced data selection use the `.loc` and `.iloc` functions. Although we call them functions, they are summoned using the `[ ]` notation. The `.loc` is primarily label-based. The common allowed inputs to `.loc` are \n",
    "* a single label,\n",
    "* a list of labels,\n",
    "* a slice object, \n",
    "* a boolean array.\n",
    "\n",
    "The `.iloc` is primarily an integer-based input. The common allowed inputs to `.iloc` are \n",
    "* a single integer,\n",
    "* a list of integers,\n",
    "* a slice object, \n",
    "* a boolean array.\n",
    "  \n",
    "When selecting from a DataFrame with `.loc` or `.iloc`, we can provide a comma-separated index, just as with NumPy. It is good to keep this [reference](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) page bookmarked.\n",
    "\n",
    "*Take note that this next command will only work if the Index is made up of integers!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[[2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the slice operator inclusive when we use `.loc`, but not inclusive when we use `.iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[2:10:4, \"GDP\":\"Generosity\":2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ.iloc[2:11:4, 3:8:2] # Same as above, but with .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.iloc[:, 2:4].describe(percentiles=[0.25, .5, .75, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Happiness Score is a left-skewed distribution. Suppose we are interested in the very happy countries. Here is how we can filter the data with a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiest = happ[happ['Happiness.Score'] > 6.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiest.Country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't a single Asian or African country in the happiest 10% of countries!\n",
    "\n",
    "We can also combine Boolean indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 happiest countries in 2015\n",
    "happ[(happ.Year == 2015) & (happ['Happiness.Rank'] <= 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "The `.info()` method will yield information on missing values, column by column. We can see there are 21 rows with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sometimes*, it is appropriate to drop rows with missing values. This can be done with the `.dropna` method. Remember that it returns a new dataframe. The original one remains unchanged, unless you include the `inplace=True` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(happ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions'></a>\n",
    "## Applying Functions to DataFrame\n",
    "\n",
    "A common task in data analysis is to apply a function to each column, or to each row. With a Pandas DataFrame, this can be achieved in a few ways, depending on how the function is to be applied:\n",
    "* To apply a function to the entire DataFrame, e.g. fitting a model, we use the `pipe` function. We shall see this later in the course.\n",
    "* To apply a function to each row or each column, we use the `apply` function.\n",
    "* To apply a function to each element, we use the `applymap` function. This is typically used with a lambda function.\n",
    "* There are several built-in functions that we can call to aggregate a column or a row. Examples of these are `count`, `sum`, `mean`, `median`, and so on. A full list can be found [here](https://pandas.pydata.org/docs/user_guide/basics.html#descriptive-statistics).\n",
    "\n",
    "Remember that the happiness dataframe contains 11 columns, but not all of them are numerical measures. Suppose we wish to count how many non-null values there are in each of the columns, apart from Happiness Rank, Country, and Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[:, 'Happiness.Score':'Dystopia.Residual'].count(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `count()` function was applied to each column (along `axis=0`). Similarly, suppose we wish to compute the standard deviation of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[:, 'Happiness.Score':'Dystopia.Residual'].std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wish to find the **range** of values for each numeric column, which we define as the maximum minus the minimum value of that column. We can apply a lambda function of our own here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happ.loc[:, 'Happiness.Score':'Dystopia.Residual'].apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between-Series operations are conducted element-wise. Note the two different ways of indexing a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ['Life.Expectancy'] / happ.Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding or Deleting Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete columns, we can use the DataFrame `.drop()` method. Unless we specify `inplace=True`, a new copy of the DataFrame will be created by `.drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete columns:\n",
    "happ.drop(columns=['GDP', 'Freedom', 'Year']).head(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new column simply by specifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a new column, that contains square root of Happiness Score.\n",
    "happ['sqrt_HS'] = np.sqrt(happ['Happiness.Score'])\n",
    "#happ.loc[:, 'sqrt_HS'] = happ['Happiness.Score'].apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were given the following classification of GDP. We can create that new feature \n",
    "as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.GDP.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.GDP.plot(kind = \"hist\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To create a new column, that bucketizes the GDP into high, low, medium\n",
    "happ['GDP_cat'] = pd.cut(happ.GDP, bins = [0, 0.5, 1.5, 1.870765686], labels = ['low', 'med', 'high'] )\n",
    "#happ.loc[:, 'GDP_cat'] = pd.cut(happ.GDP, bins = [0, 0.5, 1.5, 2], labels = ['low', 'med', 'high'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.loc[0:5, ['GDP', 'GDP_cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical'></a>\n",
    "## Categorical Variables\n",
    "\n",
    "### Tables of Counts\n",
    "\n",
    "To summarise categorical variables, one option is to use tables. These tables could present counts of levels, or proportions.\n",
    "\n",
    "When assessing the relationship between categorical variables, the simplest option is to print a table of counts.\n",
    "\n",
    "When we wish to assess a variable, or an aggregation of it, conditional on two or more categorical levels, we use a pivot table.\n",
    "\n",
    "Suppose that, in the happiness dataset, we wish to understand if the distribution of high, low, med GDP has changed in the three years. We can set up a cross-table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(happ.Year, happ.GDP_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that in 2017, the tails of the distribution changed the most. We can compute the proportion of high/med/low within each year by adding the normalize argument. What else piques your curiosity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_out = pd.crosstab(happ.Year, happ.GDP_cat, normalize = 'index') \n",
    "tab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_out.plot(kind = 'bar', figsize = (10, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does Happiness Score change with GDP category (as we have defined them) over the years? To introduce a third variable, we shall have to create a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.pivot_table(index = 'Year', columns = 'GDP_cat', values = 'Happiness.Score', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complicate things further, suppose we compare SEA nations to non-SEA nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEA_nations = ['Singapore', 'Malaysia', 'Indonesia', 'Laos', 'Thailand', 'Vietnam', 'Myanmar']\n",
    "happ['region'] = happ.Country.apply(lambda x: 'SEA' if x in SEA_nations else 'not_SEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.pivot_table(index = ['region', 'Year'], columns = 'GDP_cat', values = 'Happiness.Score', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split'></a>\n",
    "## Split-Apply-Transform\n",
    "\n",
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.groupby(['Country', 'Year'])['Happiness.Score'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.groupby('Country')['Happiness.Score'].mean().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.plot(x = 'Generosity', y = 'Life.Expectancy', kind = 'scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ[happ.Generosity > 0.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happ.Generosity.plot(kind = 'box');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multiple'></a>\n",
    "##  Working with Multiple DataFrames\n",
    "\n",
    "The following two datasets contain information on the matches played at the 2018 FIFA world cup:\n",
    "\n",
    "* `match_schedule.xlsx` - contains the schedule of all 64 matches and their outcomes.\n",
    "* `weatherTable.xlsx` - contains information on the weather at the venue of each match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_excel('../data/weatherTable.xlsx')\n",
    "schedule = pd.read_excel('../data/match_schedule.xlsx')\n",
    "# You may need to install openpyxl (at command prompt, run pip install openpyxl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both dataframes have a match id column. When we want to merge two dataframes, they have to have common column(s). There are two main types of joins: inner and outer joins. Outer joins are left, right or full joins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figs/join-outer.png\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner joins keep only the rows that are present in **both** dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figs/join-inner.png\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pandas, things  get an additional layer of complication. Instead of merging on the column, one can merge based on the index. This will only be appropriate if both indices are of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_weather = pd.merge(schedule, weather, on = 'match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_weather.temperature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_weather.groupby('venue').temperature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_weather.groupby('venue')[['temperature', 'wind_speed']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other pandas functions for joining datasets that you should be aware of is `pd.concat`. This is appropriate when you are adding new rows to a dataframe (ingore the index) or new columns (may need to ignore index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='ref'></a>\n",
    "# 3. References and Links\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "1. [Numpy user manual](https://numpy.org/doc/stable/user/index.html)\n",
    "2. [10-minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) User manuals and references can be found through here.\n",
    "3. [Selection with Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) Using .loc and .iloc.\n",
    "4. [World Happiness Report](https://worldhappiness.report/ed/2017/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
